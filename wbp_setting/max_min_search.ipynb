{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pressure_fact</th>\n",
       "      <th>pressure_smoothed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-01-11</td>\n",
       "      <td>86.8000</td>\n",
       "      <td>87.119052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-01-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.165231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-01-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.788705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-01-20</td>\n",
       "      <td>86.8000</td>\n",
       "      <td>86.648587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-01-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.490297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3048</th>\n",
       "      <td>2025-03-11</td>\n",
       "      <td>74.2344</td>\n",
       "      <td>74.448930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3049</th>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.386106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3050</th>\n",
       "      <td>2025-03-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.330345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3051</th>\n",
       "      <td>2025-03-15</td>\n",
       "      <td>74.2344</td>\n",
       "      <td>74.240182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3052</th>\n",
       "      <td>2025-03-21</td>\n",
       "      <td>74.0190</td>\n",
       "      <td>74.143652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3053 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  pressure_fact  pressure_smoothed\n",
       "0    2005-01-11        86.8000          87.119052\n",
       "1    2005-01-12            NaN          87.165231\n",
       "2    2005-01-19            NaN          86.788705\n",
       "3    2005-01-20        86.8000          86.648587\n",
       "4    2005-01-21            NaN          86.490297\n",
       "...         ...            ...                ...\n",
       "3048 2025-03-11        74.2344          74.448930\n",
       "3049 2025-03-12            NaN          74.386106\n",
       "3050 2025-03-13            NaN          74.330345\n",
       "3051 2025-03-15        74.2344          74.240182\n",
       "3052 2025-03-21        74.0190          74.143652\n",
       "\n",
       "[3053 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'data/well_data.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def find_extremes_improved(df, min_distance_days=90, prominence_percent=3, max_cycle_days=400):\n",
    "    \"\"\"\n",
    "    Улучшенный алгоритм поиска экстремумов для циклических данных с годовыми циклами.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Копируем датафрейм\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    # Преобразуем дату\n",
    "    if not pd.api.types.is_datetime64_any_dtype(result_df['date']):\n",
    "        result_df['date'] = pd.to_datetime(result_df['date'], format='%d.%m.%Y')\n",
    "    \n",
    "    # Сортируем по дате\n",
    "    result_df = result_df.sort_values('date').reset_index(drop=True)\n",
    "    \n",
    "    # Инициализируем колонки\n",
    "    result_df['maxima'] = np.nan\n",
    "    result_df['minima'] = np.nan\n",
    "    \n",
    "    # Получаем значения\n",
    "    pressures = result_df['pressure_smoothed'].values\n",
    "    dates = result_df['date'].values\n",
    "    n = len(pressures)\n",
    "    \n",
    "    # Вычисляем среднее значение для определения значимости\n",
    "    avg_pressure = np.nanmean(pressures)\n",
    "    min_prominence = avg_pressure * (prominence_percent / 100)\n",
    "    \n",
    "    # Конвертируем расстояние в днях в индексы\n",
    "    # Оцениваем среднее расстояние между точками\n",
    "    if n > 1:\n",
    "        avg_days_between_points = (dates[-1] - dates[0]).astype('timedelta64[D]').astype(int) / (n - 1)\n",
    "        min_distance_points = int(min_distance_days / avg_days_between_points)\n",
    "    else:\n",
    "        min_distance_points = 30\n",
    "    \n",
    "    # Используем scipy.signal для поиска пиков (если установлен)\n",
    "    try:\n",
    "        from scipy.signal import find_peaks\n",
    "        use_scipy = True\n",
    "    except ImportError:\n",
    "        use_scipy = False\n",
    "        print(\"Библиотека scipy не установлена. Используется упрощенный алгоритм.\")\n",
    "    \n",
    "    if use_scipy:\n",
    "        # Находим максимумы\n",
    "        max_peaks, _ = find_peaks(pressures, \n",
    "                                  distance=min_distance_points,\n",
    "                                  prominence=min_prominence)\n",
    "        \n",
    "        # Находим минимумы (инвертируем сигнал)\n",
    "        min_peaks, _ = find_peaks(-pressures, \n",
    "                                  distance=min_distance_points,\n",
    "                                  prominence=min_prominence)\n",
    "        \n",
    "        maxima_indices = max_peaks.tolist()\n",
    "        minima_indices = min_peaks.tolist()\n",
    "    else:\n",
    "        # Упрощенный алгоритм без scipy\n",
    "        maxima_indices = []\n",
    "        minima_indices = []\n",
    "        \n",
    "        # Ищем локальные максимумы\n",
    "        for i in range(min_distance_points, n - min_distance_points):\n",
    "            window = pressures[i-min_distance_points//2:i+min_distance_points//2+1]\n",
    "            if pressures[i] == np.max(window) and pressures[i] != window[0] and pressures[i] != window[-1]:\n",
    "                # Проверяем значимость\n",
    "                left_min = np.min(pressures[max(0, i-min_distance_points):i])\n",
    "                right_min = np.min(pressures[i:min(n, i+min_distance_points)])\n",
    "                prominence_val = pressures[i] - max(left_min, right_min)\n",
    "                \n",
    "                if prominence_val > min_prominence:\n",
    "                    maxima_indices.append(i)\n",
    "        \n",
    "        # Ищем локальные минимумы\n",
    "        for i in range(min_distance_points, n - min_distance_points):\n",
    "            window = pressures[i-min_distance_points//2:i+min_distance_points//2+1]\n",
    "            if pressures[i] == np.min(window) and pressures[i] != window[0] and pressures[i] != window[-1]:\n",
    "                # Проверяем значимость\n",
    "                left_max = np.max(pressures[max(0, i-min_distance_points):i])\n",
    "                right_max = np.max(pressures[i:min(n, i+min_distance_points)])\n",
    "                prominence_val = max(left_max, right_max) - pressures[i]\n",
    "                \n",
    "                if prominence_val > min_prominence:\n",
    "                    minima_indices.append(i)\n",
    "    \n",
    "    # Фильтруем экстремумы, чтобы они чередовались\n",
    "    filtered_maxima = []\n",
    "    filtered_minima = []\n",
    "    \n",
    "    # Объединяем и сортируем все экстремумы\n",
    "    all_extrema = sorted([(idx, 'max', pressures[idx]) for idx in maxima_indices] + \n",
    "                         [(idx, 'min', pressures[idx]) for idx in minima_indices])\n",
    "    \n",
    "    # Проходим по всем экстремумам и выбираем наиболее значимые\n",
    "    i = 0\n",
    "    while i < len(all_extrema):\n",
    "        current_idx, current_type, current_val = all_extrema[i]\n",
    "        \n",
    "        if current_type == 'max':\n",
    "            # Ищем ближайший минимум после этого максимума\n",
    "            min_candidates = []\n",
    "            for j in range(i+1, len(all_extrema)):\n",
    "                idx2, type2, val2 = all_extrema[j]\n",
    "                if type2 == 'min':\n",
    "                    # Проверяем расстояние\n",
    "                    days_diff = (dates[idx2] - dates[current_idx]).astype('timedelta64[D]').astype(int)\n",
    "                    if 30 < days_diff < 300:  # Минимум должен быть в пределах 300 дней\n",
    "                        min_candidates.append((idx2, val2, days_diff))\n",
    "            \n",
    "            if min_candidates:\n",
    "                # Выбираем самый глубокий минимум\n",
    "                best_min_idx = min(min_candidates, key=lambda x: x[1])[0]\n",
    "                \n",
    "                # Проверяем, что разница достаточно большая\n",
    "                if pressures[current_idx] - pressures[best_min_idx] > min_prominence:\n",
    "                    filtered_maxima.append(current_idx)\n",
    "                    filtered_minima.append(best_min_idx)\n",
    "                    \n",
    "                    # Пропускаем обработанные точки\n",
    "                    while i < len(all_extrema) and all_extrema[i][0] != best_min_idx:\n",
    "                        i += 1\n",
    "        i += 1\n",
    "    \n",
    "    # Если все еще мало экстремумов, используем более простой подход\n",
    "    if len(filtered_maxima) < 5:\n",
    "        print(f\"Найдено слишком мало экстремумов: {len(filtered_maxima)} максимумов\")\n",
    "        print(\"Используем альтернативный алгоритм...\")\n",
    "        \n",
    "        # Альтернативный простой алгоритм\n",
    "        filtered_maxima = []\n",
    "        filtered_minima = []\n",
    "        \n",
    "        # Ищем максимумы каждые ~180 дней (полгода)\n",
    "        i = 0\n",
    "        while i < n:\n",
    "            # Определяем окно поиска\n",
    "            window_start = i\n",
    "            window_end = min(n, i + 180 // int(avg_days_between_points) if avg_days_between_points > 0 else i + 100)\n",
    "            \n",
    "            if window_end - window_start > 10:\n",
    "                # Ищем максимум в окне\n",
    "                max_idx = window_start + np.argmax(pressures[window_start:window_end])\n",
    "                max_val = pressures[max_idx]\n",
    "                \n",
    "                # Ищем минимум после максимума\n",
    "                if max_idx + 50 < n:\n",
    "                    min_window_start = max_idx + 30 // int(avg_days_between_points) if avg_days_between_points > 0 else max_idx + 15\n",
    "                    min_window_end = min(n, min_window_start + 150 // int(avg_days_between_points) if avg_days_between_points > 0 else min_window_start + 75)\n",
    "                    \n",
    "                    if min_window_end - min_window_start > 10:\n",
    "                        min_idx = min_window_start + np.argmin(pressures[min_window_start:min_window_end])\n",
    "                        min_val = pressures[min_idx]\n",
    "                        \n",
    "                        # Проверяем значимость\n",
    "                        if max_val - min_val > min_prominence:\n",
    "                            filtered_maxima.append(max_idx)\n",
    "                            filtered_minima.append(min_idx)\n",
    "                            \n",
    "                            i = min_idx\n",
    "                            continue\n",
    "            \n",
    "            i += 30 // int(avg_days_between_points) if avg_days_between_points > 0 else i + 15\n",
    "    \n",
    "    # Заполняем датафрейм\n",
    "    for idx in filtered_maxima:\n",
    "        result_df.loc[idx, 'maxima'] = pressures[idx]\n",
    "    \n",
    "    for idx in filtered_minima:\n",
    "        result_df.loc[idx, 'minima'] = pressures[idx]\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "def find_extremes_improved_v2(df, min_distance_days=60, prominence_percent=2, \n",
    "                              max_cycle_days=400, edge_buffer_days=30):\n",
    "    \"\"\"\n",
    "    Улучшенный алгоритм поиска экстремумов для циклических данных с годовыми циклами.\n",
    "    \n",
    "    Параметры:\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Датафрейм с колонками ['date', 'pressure_smoothed']\n",
    "    min_distance_days : int\n",
    "        Минимальное расстояние между экстремумами в днях (по умолчанию 60)\n",
    "    prominence_percent : float\n",
    "        Минимальная значимость экстремума в процентах от среднего значения (по умолчанию 2%)\n",
    "    max_cycle_days : int\n",
    "        Максимальная длина цикла в днях (по умолчанию 400)\n",
    "    edge_buffer_days : int\n",
    "        Буфер для обработки краев данных в днях (по умолчанию 30)\n",
    "    \n",
    "    Возвращает:\n",
    "    -----------\n",
    "    pandas.DataFrame\n",
    "        Датафрейм с добавленными колонками 'maxima' и 'minima'\n",
    "    \"\"\"\n",
    "    \n",
    "    # Копируем датафрейм\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    # Преобразуем дату\n",
    "    if not pd.api.types.is_datetime64_any_dtype(result_df['date']):\n",
    "        result_df['date'] = pd.to_datetime(result_df['date'], format='%d.%m.%Y')\n",
    "    \n",
    "    # Сортируем по дате\n",
    "    result_df = result_df.sort_values('date').reset_index(drop=True)\n",
    "    \n",
    "    # Инициализируем колонки\n",
    "    result_df['maxima'] = np.nan\n",
    "    result_df['minima'] = np.nan\n",
    "    \n",
    "    # Получаем значения\n",
    "    pressures = result_df['pressure_smoothed'].values\n",
    "    dates = result_df['date'].values\n",
    "    n = len(pressures)\n",
    "    \n",
    "    if n < 10:\n",
    "        print(\"Слишком мало данных для поиска экстремумов\")\n",
    "        return result_df\n",
    "    \n",
    "    # Вычисляем среднее значение для определения значимости\n",
    "    avg_pressure = np.nanmean(pressures)\n",
    "    min_prominence = avg_pressure * (prominence_percent / 100)\n",
    "    \n",
    "    # Конвертируем расстояние в днях в индексы\n",
    "    if n > 1:\n",
    "        avg_days_between_points = (dates[-1] - dates[0]).astype('timedelta64[D]').astype(int) / (n - 1)\n",
    "        min_distance_points = max(5, int(min_distance_days / avg_days_between_points))\n",
    "    else:\n",
    "        min_distance_points = 30\n",
    "    \n",
    "    print(f\"Всего точек: {n}\")\n",
    "    print(f\"Среднее давление: {avg_pressure:.2f}\")\n",
    "    print(f\"Минимальная значимость: {min_prominence:.2f}\")\n",
    "    print(f\"Минимальное расстояние в точках: {min_distance_points}\")\n",
    "    \n",
    "    # Инициализируем списки для экстремумов\n",
    "    all_maxima_indices = []\n",
    "    all_minima_indices = []\n",
    "    \n",
    "    # 1. Поиск с помощью scipy.signal.find_peaks (основной метод)\n",
    "    try:\n",
    "        # Находим максимумы\n",
    "        max_peaks, max_properties = find_peaks(\n",
    "            pressures, \n",
    "            distance=min_distance_points,\n",
    "            prominence=min_prominence,\n",
    "            width=min_distance_points//3,  # Учитываем ширину пика\n",
    "            rel_height=0.5\n",
    "        )\n",
    "        \n",
    "        # Находим минимумы (инвертируем сигнал)\n",
    "        min_peaks, min_properties = find_peaks(\n",
    "            -pressures, \n",
    "            distance=min_distance_points,\n",
    "            prominence=min_prominence,\n",
    "            width=min_distance_points//3,\n",
    "            rel_height=0.5\n",
    "        )\n",
    "        \n",
    "        all_maxima_indices = list(max_peaks)\n",
    "        all_minima_indices = list(min_peaks)\n",
    "        \n",
    "        print(f\"Найдено {len(all_maxima_indices)} максимумов и {len(all_minima_indices)} минимумов через find_peaks\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при использовании find_peaks: {e}\")\n",
    "        all_maxima_indices = []\n",
    "        all_minima_indices = []\n",
    "    \n",
    "    # 2. Дополнительный поиск по годовым циклам\n",
    "    years = result_df['date'].dt.year.unique()\n",
    "    yearly_extremes = []\n",
    "    \n",
    "    for year in years:\n",
    "        year_mask = result_df['date'].dt.year == year\n",
    "        year_indices = np.where(year_mask)[0]\n",
    "        \n",
    "        if len(year_indices) > 30:  # Минимум 30 точек в году\n",
    "            year_pressures = pressures[year_indices]\n",
    "            \n",
    "            # Находим максимум года\n",
    "            year_max_idx_local = np.argmax(year_pressures)\n",
    "            year_max_idx = year_indices[year_max_idx_local]\n",
    "            year_max_val = year_pressures[year_max_idx_local]\n",
    "            \n",
    "            # Находим минимум года\n",
    "            year_min_idx_local = np.argmin(year_pressures)\n",
    "            year_min_idx = year_indices[year_min_idx_local]\n",
    "            year_min_val = year_pressures[year_min_idx_local]\n",
    "            \n",
    "            # Проверяем, что это действительно экстремум в окрестности\n",
    "            window_size = min(50, len(year_indices)//3)\n",
    "            \n",
    "            # Для максимума\n",
    "            if year_max_idx_local >= window_size and year_max_idx_local < len(year_indices) - window_size:\n",
    "                window = year_pressures[year_max_idx_local-window_size:year_max_idx_local+window_size+1]\n",
    "                if year_max_val == np.max(window):\n",
    "                    yearly_extremes.append((year_max_idx, 'max', year_max_val))\n",
    "            \n",
    "            # Для минимума\n",
    "            if year_min_idx_local >= window_size and year_min_idx_local < len(year_indices) - window_size:\n",
    "                window = year_pressures[year_min_idx_local-window_size:year_min_idx_local+window_size+1]\n",
    "                if year_min_val == np.min(window):\n",
    "                    yearly_extremes.append((year_min_idx, 'min', year_min_val))\n",
    "    \n",
    "    print(f\"Найдено {len([e for e in yearly_extremes if e[1]=='max'])} максимумов и \"\n",
    "          f\"{len([e for e in yearly_extremes if e[1]=='min'])} минимумов по годам\")\n",
    "    \n",
    "    # 3. Проверка краевых точек\n",
    "    edge_extremes = []\n",
    "    \n",
    "    # Проверяем первые edge_buffer_days дней\n",
    "    edge_points = int(edge_buffer_days / avg_days_between_points) if avg_days_between_points > 0 else 30\n",
    "    edge_points = min(edge_points, n//4)\n",
    "    \n",
    "    if edge_points > 5:\n",
    "        # Проверяем начало данных\n",
    "        start_window = pressures[:edge_points*2]\n",
    "        if len(start_window) > 0:\n",
    "            start_max_idx = np.argmax(start_window)\n",
    "            start_max_val = start_window[start_max_idx]\n",
    "            start_min_idx = np.argmin(start_window)\n",
    "            start_min_val = start_window[start_min_idx]\n",
    "            \n",
    "            # Проверяем значимость\n",
    "            if start_max_idx > 0 and start_max_idx < len(start_window)-1:\n",
    "                if start_max_val - start_min_val > min_prominence:\n",
    "                    edge_extremes.append((start_max_idx, 'max', start_max_val))\n",
    "                    edge_extremes.append((start_min_idx, 'min', start_min_val))\n",
    "        \n",
    "        # Проверяем конец данных\n",
    "        end_window = pressures[-edge_points*2:]\n",
    "        if len(end_window) > 0:\n",
    "            end_max_idx = n - len(end_window) + np.argmax(end_window)\n",
    "            end_max_val = pressures[end_max_idx]\n",
    "            end_min_idx = n - len(end_window) + np.argmin(end_window)\n",
    "            end_min_val = pressures[end_min_idx]\n",
    "            \n",
    "            if end_max_idx > n - len(end_window) and end_max_idx < n-1:\n",
    "                if end_max_val - end_min_val > min_prominence:\n",
    "                    edge_extremes.append((end_max_idx, 'max', end_max_val))\n",
    "                    edge_extremes.append((end_min_idx, 'min', end_min_val))\n",
    "    \n",
    "    print(f\"Найдено {len([e for e in edge_extremes if e[1]=='max'])} максимумов и \"\n",
    "          f\"{len([e for e in edge_extremes if e[1]=='min'])} минимумов на краях\")\n",
    "    \n",
    "    # 4. Объединяем все найденные экстремумы\n",
    "    all_extrema_dict = {'max': [], 'min': []}\n",
    "    \n",
    "    # Добавляем экстремумы из find_peaks\n",
    "    for idx in all_maxima_indices:\n",
    "        all_extrema_dict['max'].append((idx, pressures[idx]))\n",
    "    for idx in all_minima_indices:\n",
    "        all_extrema_dict['min'].append((idx, pressures[idx]))\n",
    "    \n",
    "    # Добавляем годовые экстремумы\n",
    "    for idx, typ, val in yearly_extremes:\n",
    "        all_extrema_dict[typ].append((idx, val))\n",
    "    \n",
    "    # Добавляем краевые экстремумы\n",
    "    for idx, typ, val in edge_extremes:\n",
    "        all_extrema_dict[typ].append((idx, val))\n",
    "    \n",
    "    # Удаляем дубликаты и сортируем\n",
    "    for typ in ['max', 'min']:\n",
    "        if all_extrema_dict[typ]:\n",
    "            # Удаляем дубликаты по индексу\n",
    "            unique_dict = {}\n",
    "            for idx, val in all_extrema_dict[typ]:\n",
    "                if idx not in unique_dict:\n",
    "                    unique_dict[idx] = val\n",
    "                elif typ == 'max' and val > unique_dict[idx]:\n",
    "                    unique_dict[idx] = val\n",
    "                elif typ == 'min' and val < unique_dict[idx]:\n",
    "                    unique_dict[idx] = val\n",
    "            \n",
    "            # Сортируем по индексу\n",
    "            all_extrema_dict[typ] = sorted([(idx, val) for idx, val in unique_dict.items()])\n",
    "    \n",
    "    print(f\"После объединения: {len(all_extrema_dict['max'])} максимумов и {len(all_extrema_dict['min'])} минимумов\")\n",
    "    \n",
    "    # 5. Фильтрация и чередование экстремумов\n",
    "    filtered_maxima = []\n",
    "    filtered_minima = []\n",
    "    \n",
    "    # Объединяем все экстремумы в один отсортированный список\n",
    "    combined_extrema = []\n",
    "    for idx, val in all_extrema_dict['max']:\n",
    "        combined_extrema.append((idx, 'max', val))\n",
    "    for idx, val in all_extrema_dict['min']:\n",
    "        combined_extrema.append((idx, 'min', val))\n",
    "    \n",
    "    combined_extrema.sort(key=lambda x: x[0])\n",
    "    \n",
    "    # Алгоритм чередования с допущениями\n",
    "    i = 0\n",
    "    last_type = None\n",
    "    last_idx = -min_distance_points * 2\n",
    "    \n",
    "    while i < len(combined_extrema):\n",
    "        idx, typ, val = combined_extrema[i]\n",
    "        \n",
    "        # Проверяем расстояние до предыдущего экстремума\n",
    "        if idx - last_idx < min_distance_points:\n",
    "            # Если слишком близко, выбираем более значимый\n",
    "            if last_type == 'max' and typ == 'max':\n",
    "                # Два максимума рядом - выбираем больший\n",
    "                if val > pressures[last_idx]:\n",
    "                    # Удаляем предыдущий, добавляем текущий\n",
    "                    if last_idx in filtered_maxima:\n",
    "                        filtered_maxima.remove(last_idx)\n",
    "                    filtered_maxima.append(idx)\n",
    "                    last_idx = idx\n",
    "                # Иначе пропускаем текущий\n",
    "            elif last_type == 'min' and typ == 'min':\n",
    "                # Два минимума рядом - выбираем меньший\n",
    "                if val < pressures[last_idx]:\n",
    "                    if last_idx in filtered_minima:\n",
    "                        filtered_minima.remove(last_idx)\n",
    "                    filtered_minima.append(idx)\n",
    "                    last_idx = idx\n",
    "            i += 1\n",
    "            continue\n",
    "        \n",
    "        # Проверяем чередование\n",
    "        if last_type is None or typ != last_type:\n",
    "            # Если это первый экстремум или типы чередуются\n",
    "            if typ == 'max':\n",
    "                filtered_maxima.append(idx)\n",
    "            else:\n",
    "                filtered_minima.append(idx)\n",
    "            \n",
    "            last_type = typ\n",
    "            last_idx = idx\n",
    "            i += 1\n",
    "        else:\n",
    "            # Если типы не чередуются, проверяем следующий экстремум\n",
    "            # Ищем ближайший экстремум другого типа в пределах max_cycle_days\n",
    "            found_alternate = False\n",
    "            max_search = min(i + 20, len(combined_extrema))\n",
    "            \n",
    "            for j in range(i + 1, max_search):\n",
    "                idx2, typ2, val2 = combined_extrema[j]\n",
    "                \n",
    "                # Проверяем расстояние в днях\n",
    "                days_diff = (dates[idx2] - dates[idx]).astype('timedelta64[D]').astype(int)\n",
    "                \n",
    "                if typ2 != typ and 30 < days_diff < max_cycle_days:\n",
    "                    # Нашли чередующийся экстремум\n",
    "                    if typ2 == 'max':\n",
    "                        filtered_maxima.append(idx2)\n",
    "                    else:\n",
    "                        filtered_minima.append(idx2)\n",
    "                    \n",
    "                    last_type = typ2\n",
    "                    last_idx = idx2\n",
    "                    i = j + 1\n",
    "                    found_alternate = True\n",
    "                    break\n",
    "            \n",
    "            if not found_alternate:\n",
    "                # Если не нашли чередующийся, пропускаем текущий\n",
    "                i += 1\n",
    "    \n",
    "    # 6. Дополнительная проверка пропущенных экстремумов\n",
    "    # Ищем крупные пропуски между экстремумами\n",
    "    all_filtered = sorted([(idx, 'max', pressures[idx]) for idx in filtered_maxima] + \n",
    "                         [(idx, 'min', pressures[idx]) for idx in filtered_minima])\n",
    "    \n",
    "    for k in range(len(all_filtered) - 1):\n",
    "        idx1, typ1, val1 = all_filtered[k]\n",
    "        idx2, typ2, val2 = all_filtered[k + 1]\n",
    "        \n",
    "        # Вычисляем расстояние в днях\n",
    "        days_diff = (dates[idx2] - dates[idx1]).astype('timedelta64[D]').astype(int)\n",
    "        \n",
    "        # Если большой пропуск (> 250 дней), ищем экстремум в середине\n",
    "        if days_diff > 250 and typ1 != typ2:\n",
    "            mid_idx = (idx1 + idx2) // 2\n",
    "            search_start = max(0, mid_idx - min_distance_points)\n",
    "            search_end = min(n, mid_idx + min_distance_points)\n",
    "            \n",
    "            if search_end - search_start > 10:\n",
    "                if typ1 == 'max':\n",
    "                    # Между максимумом и минимумом должен быть минимум\n",
    "                    search_min_idx = search_start + np.argmin(pressures[search_start:search_end])\n",
    "                    search_min_val = pressures[search_min_idx]\n",
    "                    \n",
    "                    # Проверяем значимость\n",
    "                    if val1 - search_min_val > min_prominence and val2 - search_min_val > min_prominence:\n",
    "                        if search_min_idx not in filtered_minima:\n",
    "                            filtered_minima.append(search_min_idx)\n",
    "                else:\n",
    "                    # Между минимумом и максимумом должен быть максимум\n",
    "                    search_max_idx = search_start + np.argmax(pressures[search_start:search_end])\n",
    "                    search_max_val = pressures[search_max_idx]\n",
    "                    \n",
    "                    # Проверяем значимость\n",
    "                    if search_max_val - val1 > min_prominence and search_max_val - val2 > min_prominence:\n",
    "                        if search_max_idx not in filtered_maxima:\n",
    "                            filtered_maxima.append(search_max_idx)\n",
    "    \n",
    "    # 7. Сортировка и удаление дубликатов\n",
    "    filtered_maxima = sorted(list(set(filtered_maxima)))\n",
    "    filtered_minima = sorted(list(set(filtered_minima)))\n",
    "    \n",
    "    print(f\"После фильтрации: {len(filtered_maxima)} максимумов и {len(filtered_minima)} минимумов\")\n",
    "    \n",
    "    # 8. Заполняем датафрейм\n",
    "    for idx in filtered_maxima:\n",
    "        if 0 <= idx < n:\n",
    "            result_df.loc[idx, 'maxima'] = pressures[idx]\n",
    "    \n",
    "    for idx in filtered_minima:\n",
    "        if 0 <= idx < n:\n",
    "            result_df.loc[idx, 'minima'] = pressures[idx]\n",
    "    \n",
    "    # 9. Дополнительная информация для отладки\n",
    "    if len(filtered_maxima) > 0 and len(filtered_minima) > 0:\n",
    "        print(f\"Первый максимум: {result_df.loc[filtered_maxima[0], 'date'].strftime('%d.%m.%Y')} = {pressures[filtered_maxima[0]]:.2f}\")\n",
    "        print(f\"Последний максимум: {result_df.loc[filtered_maxima[-1], 'date'].strftime('%d.%m.%Y')} = {pressures[filtered_maxima[-1]]:.2f}\")\n",
    "        print(f\"Первый минимум: {result_df.loc[filtered_minima[0], 'date'].strftime('%d.%m.%Y')} = {pressures[filtered_minima[0]]:.2f}\")\n",
    "        print(f\"Последний минимум: {result_df.loc[filtered_minima[-1], 'date'].strftime('%d.%m.%Y')} = {pressures[filtered_minima[-1]]:.2f}\")\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего точек: 3053\n",
      "Среднее давление: 85.28\n",
      "Минимальная значимость: 1.71\n",
      "Минимальное расстояние в точках: 24\n",
      "Найдено 20 максимумов и 20 минимумов через find_peaks\n",
      "Найдено 3 максимумов и 12 минимумов по годам\n",
      "Найдено 1 максимумов и 1 минимумов на краях\n",
      "После объединения: 21 максимумов и 21 минимумов\n",
      "После фильтрации: 21 максимумов и 20 минимумов\n",
      "Первый максимум: 12.01.2005 = 87.17\n",
      "Последний максимум: 31.10.2024 = 106.26\n",
      "Первый минимум: 11.05.2005 = 67.74\n",
      "Последний минимум: 12.05.2024 = 71.46\n"
     ]
    }
   ],
   "source": [
    "df_with_extrems = find_extremes_improved_v2(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_extrems.to_clipboard(index=False, excel=True, sep=\";\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
